{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from AGGjobs import *\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "# from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='database_operations.log',\n",
    "    level=logging.DEBUG,  # Changed to DEBUG to capture all messages\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w'  # Ensure the file is overwritten each time for clean logs\n",
    ")\n",
    "def log_execution_time(job_name, start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(f\"Execution time for {job_name}: {execution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)\n",
    "    db.connect_JDBC()\n",
    "\n",
    "    # Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    # logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "\n",
    "    # Job execution without a loop\n",
    "        \n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_404_AGG_TAGGREGATE...\")\n",
    "\n",
    "    # AUD_404_AGG_TAGGREGATE(config, db,  execution_date)\n",
    "    # log_execution_time(\"AUD_404_AGG_TAGGREGATE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_405_AGG_TMAP...\")\n",
    "    AUD_405_AGG_TMAP(config, db,  execution_date)\n",
    "    log_execution_time(\"AUD_405_AGG_TMAP\", start_time)\n",
    "    # Job execution without a loop\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_405_AGG_TXMLMAP...\")\n",
    "    # AUD_405_AGG_TXMLMAP(config, db,  execution_date)\n",
    "    # log_execution_time(\"AUD_405_AGG_TXMLMAP\", start_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 34 (2979018070.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 35\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample input DataFrame (input_df)\n",
    "input_data = {\n",
    "    'rowName': ['access', 'access', 'access', 'access', 'access'],\n",
    "    'nameColumnInput': ['abris', 'accessibilite', 'annee_pose', 'arret', 'arret_pp'],\n",
    "    'composant': ['tMap_2', 'tMap_2', 'tMap_2', 'tMap_2', 'tMap_2'],\n",
    "    'NameJob': ['KEO_ETL_MOBIREPORT_LoadBDDAccess']*5,\n",
    "    'NameProject': ['KEOLISTOURS']*5\n",
    "}\n",
    "\n",
    "input_df = pd.DataFrame(input_data)\n",
    "\n",
    "# Simulated DataFrames for joins\n",
    "aud_agg_tmapinputinoutput_data = {\n",
    "    'rowName': ['access', 'access', 'access', 'access'],\n",
    "    'NameRowInput': ['abris', 'accessibilite', 'annee_pose', 'arret'],\n",
    "    'composant': ['tMap_2']*4,\n",
    "    'NameJob': ['KEO_ETL_MOBIREPORT_LoadBDDAccess']*4,\n",
    "    'NameProject': ['KEOLISTOURS']*4\n",
    "}\n",
    "aud_agg_tmapinputinoutput_df = pd.DataFrame(aud_agg_tmapinputinoutput_data)\n",
    "\n",
    "aud_agg_tmapinputinfilteroutput_data = {\n",
    "    'rowName': ['access', 'access', 'access'],\n",
    "    'NameRowInput': ['abris', 'accessibilite', 'annee_pose'],\n",
    "    'composant': ['tMap_2']*3,\n",
    "    'NameProject': ['KEOLISTOURS']*3,\n",
    "    'NameJob': ['KEO_ETL_MOBIREPORT_LoadBDDAccess']*3\n",
    "}\n",
    "aud_agg_tmapinputinfilteroutput_df = pd.DataFrame(aud_agg_tmapinputinfilteroutput_data)\n",
    "\n",
    "# Function for the join operation\n",
    "def catch_inner_join_rejects(left_df, right_df, left_join_keys, right_join_keys):\n",
    "    \n",
    "    logging.info(\"Starting inner join rejection detection.\")\n",
    "    logging.debug(f\"Left DataFrame shape: {left_df.shape}\")\n",
    "    logging.debug(f\"Right DataFrame shape: {right_df.shape}\")\n",
    "\n",
    "    # Perform a left join to detect left rejects\n",
    "    logging.info(\"Performing left join to detect rows rejected from the left DataFrame.\")\n",
    "    left_join_df = pd.merge(\n",
    "        left_df,\n",
    "        right_df,\n",
    "        left_on=left_join_keys,\n",
    "        right_on=right_join_keys,\n",
    "        how='left',\n",
    "        indicator=True  # Adds a '_merge' column to indicate join status\n",
    "    )\n",
    "    left_rejects = left_join_df[left_join_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    logging.info(f\"Detected {len(left_rejects)} left rejects.\")\n",
    "    logging.debug(f\"Left rejects sample:\\n{left_rejects.head()}\")\n",
    "\n",
    "    # Perform a right join to detect right rejects\n",
    "    logging.info(\"Performing right join to detect rows rejected from the right DataFrame.\")\n",
    "    right_join_df = pd.merge(\n",
    "        left_df,\n",
    "        right_df,\n",
    "        left_on=left_join_keys,\n",
    "        right_on=right_join_keys,\n",
    "        how='right',\n",
    "        indicator=True  # Adds a '_merge' column to indicate join status\n",
    "    )\n",
    "    right_rejects = right_join_df[right_join_df['_merge'] == 'right_only'].drop(columns=['_merge'])\n",
    "    logging.info(f\"Detected {len(right_rejects)} right rejects.\")\n",
    "    logging.debug(f\"Right rejects sample:\\n{right_rejects.head()}\")\n",
    "\n",
    "    # Combine left and right rejects\n",
    "    logging.info(\"Combining left and right rejects for overall analysis.\")\n",
    "    all_rejects = pd.concat([left_rejects, right_rejects], ignore_index=True)\n",
    "\n",
    "    # Optionally, remove duplicates if you expect overlaps\n",
    "    all_rejects = all_rejects.drop_duplicates()\n",
    "\n",
    "    logging.debug(f\"Total rejects detected: {len(all_rejects)}.\")\n",
    "    logging.debug(f\"Combined rejects sample:\\n{all_rejects.head()}\")\n",
    "\n",
    "    logging.info(\"Finished inner join rejection detection.\")\n",
    "    return all_rejects\n",
    "\n",
    "# Step 3: Testing the function\n",
    "# First, rename 'nameColumnInput' to 'NameRowInput' in input_df for consistency\n",
    "input_df = input_df.rename(columns={\"nameColumnInput\": \"NameRowInput\"})\n",
    "\n",
    "# Test the join function sequentially with multiple DataFrames\n",
    "df = catch_inner_join_rejects(input_df, aud_agg_tmapinputinoutput_df, \n",
    "                               ['rowName', 'NameRowInput', 'composant', 'NameJob', 'NameProject'],\n",
    "                               ['rowName', 'NameRowInput', 'composant', 'NameJob', 'NameProject'])\n",
    "\n",
    "df1 = catch_inner_join_rejects(df, aud_agg_tmapinputinfilteroutput_df,\n",
    "                                ['rowName', 'NameRowInput', 'composant', 'NameProject', 'NameJob'],\n",
    "                                ['rowName', 'NameRowInput', 'composant', 'NameProject', 'NameJob'])\n",
    "\n",
    "# Output the result of the final rejection data\n",
    "print(\"Final rejected rows:\")\n",
    "print(df1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "# Load configuration from config.yaml\n",
    "config_file = \"config.yaml\"\n",
    "config = Config(config_file)\n",
    "\n",
    "# Retrieve JDBC parameters and create a Database instance\n",
    "jdbc_params = config.get_jdbc_parameters()\n",
    "logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "# Initialize Database instance and set JDBC parameters\n",
    "db = Database(jdbc_params)\n",
    "db.set_jdbc_parameters(jdbc_params)\n",
    "db.connect_JDBC()  # Test the JDBC connection\n",
    "\n",
    "# Get the screenshots directory from configuration\n",
    "screenshots_directory = config.get_param('Directories', 'screenshots_directory')\n",
    "logging.debug(f\"screenshots_directory: {screenshots_directory}\")\n",
    "\n",
    "# Initialize XMLParser and parse screenshot files from the directory\n",
    "xml_parser = XMLParser()  # Initialize with required arguments if needed\n",
    "parsed_files_items = xml_parser.loop_parse_screenshots(screenshots_directory)\n",
    "\n",
    "# Log the parsed screenshot data for debugging\n",
    "logging.debug(f\"Parsed Files Data: {parsed_files_items}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "import logging\n",
    "from jobs import *\n",
    "\n",
    "def main():\n",
    "    db = None\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)  # Set JDBC parameters if needed\n",
    "    db.connect_JDBC()  # Test the JDBC connection\n",
    "\n",
    "    #  Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    #  Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "\n",
    "    # Step 3: Parse screenshot files from the directory\n",
    "    screenshots_directory = config.get_param('Directories', 'screenshots_directory')\n",
    "\n",
    "    if not os.path.isdir(screenshots_directory):\n",
    "        logging.error(\"Directory not found: %s\", screenshots_directory)\n",
    "        return\n",
    "\n",
    "    xml_parser = XMLParser()\n",
    "\n",
    "    # Assuming the `loop_parse_screenshots` method parses all screenshot XMLs in the directory\n",
    "    parsed_files_items = xml_parser.loop_parse_screenshots(screenshots_directory)\n",
    "    AUD_701_CONVERTSCREENSHOT(config, db, parsed_files_items,execution_date,local_to_dbbrut_query_results)\n",
    "    if parsed_files_items:\n",
    "        logging.info(\"Parsed screenshot data: %s\", parsed_files_items)  # Log parsed data\n",
    "    else:\n",
    "        logging.warning(\"No screenshot data found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)  # Set up logging\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n",
      "Error executing SELECT query: java.sql.SQLSyntaxErrorException: Table 'sqops_dataraise.aud_vartable_xml' doesn't exist\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from jobs import *\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='database_operations.log',\n",
    "    level=logging.DEBUG,  # Changed to DEBUG to capture all messages\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w'  # Ensure the file is overwritten each time for clean logs\n",
    ")\n",
    "\n",
    "def log_execution_time(job_name, start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(f\"Execution time for {job_name}: {execution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    # logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)\n",
    "    db.connect_JDBC()\n",
    "\n",
    "    # Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    # Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    # logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "    items_directory = config.get_param('Directories', 'items_directory')\n",
    "    xml_parser = XMLParser()\n",
    "    parsed_files_data = xml_parser.loop_parse_items(items_directory)\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_data}\")\n",
    "\n",
    "    # Job execution without a loop\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_301_ALIMELEMENTNODE...\")\n",
    "    AUD_301_ALIMELEMENTNODE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_301_ALIMELEMENTNODE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_302_ALIMCONTEXTJOB...\")\n",
    "    AUD_302_ALIMCONTEXTJOB(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_302_ALIMCONTEXTJOB\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_303_ALIMNODE...\")\n",
    "    AUD_303_ALIMNODE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_303_ALIMNODE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_303_BIGDATA_PARAMETERS...\")\n",
    "    AUD_303_BIGDATA_PARAMETERS(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_303_BIGDATA_PARAMETERS\", start_time)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_305_ALIMVARTABLE_XML...\")\n",
    "    AUD_305_ALIMVARTABLE_XML(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_305_ALIMVARTABLE_XML\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_305_ALIMVARTABLE...\")\n",
    "    AUD_305_ALIMVARTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_305_ALIMVARTABLE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_306_ALIMOUTPUTTABLE...\")\n",
    "    AUD_306_ALIMOUTPUTTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_306_ALIMOUTPUTTABLE\", start_time)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_307_ALIMINPUTTABLE_XML...\")\n",
    "    AUD_307_ALIMINPUTTABLE_XML(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_307_ALIMINPUTTABLE_XML\", start_time)\n",
    "\n",
    "    #i need to update it\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_307_ALIMINPUTTABLE...\")\n",
    "    # AUD_307_ALIMINPUTTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    # log_execution_time(\"AUD_307_ALIMINPUTTABLE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_308_ALIMCONNECTIONCOMPONENT...\")\n",
    "    AUD_308_ALIMCONNECTIONCOMPONENT(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_308_ALIMCONNECTIONCOMPONENT\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_309_ALIMELEMENTPARAMETER...\")\n",
    "    AUD_309_ALIMELEMENTPARAMETER(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_309_ALIMELEMENTPARAMETER\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_309_ALIMROUTINES...\")\n",
    "    AUD_309_ALIMROUTINES(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_309_ALIMROUTINES\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_310_ALIMLIBRARY...\")\n",
    "    AUD_310_ALIMLIBRARY(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_310_ALIMLIBRARY\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_311_ALIMELEMENTVALUENODE...\")\n",
    "    AUD_311_ALIMELEMENTVALUENODE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_311_ALIMELEMENTVALUENODE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_312_ALIMJOBFILS...\")\n",
    "    AUD_312_ALIMJOBFILS(config, db, parsed_files_data, execution_date)\n",
    "    log_execution_time(\"AUD_312_ALIMJOBFILS\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_314_ALIMSUBJOBS_OPT...\")\n",
    "    AUD_314_ALIMSUBJOBS_OPT(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_314_ALIMSUBJOBS_OPT\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_315_DELETEINACTIFNODES...\")\n",
    "    AUD_315_DELETEINACTIFNODES(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_315_DELETEINACTIFNODES\", start_time)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_317_ALIMJOBSERVERPROPRETY...\")\n",
    "    # AUD_317_ALIMJOBSERVERPROPRETY(config, db, parsed_files_data, items_directory)\n",
    "    # log_execution_time(\"AUD_317_ALIMJOBSERVERPROPRETY\", start_time)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_318_ALIMCONFQUARTZ...\")\n",
    "    # AUD_318_ALIMCONFQUARTZ(config, db, parsed_files_data, items_directory)\n",
    "    # log_execution_time(\"AUD_318_ALIMCONFQUARTZ\", start_time)\n",
    "\n",
    "    parsed_files_properties = xml_parser.loop_parse_properties(items_directory)\n",
    "    logging.debug(f\"Parsed Files Data: {parsed_files_properties}\")\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_319_ALIMDOCCONTEXTGROUP...\")\n",
    "    AUD_319_ALIMDOCCONTEXTGROUP(config, db, parsed_files_properties)\n",
    "    log_execution_time(\"AUD_319_ALIMDOCCONTEXTGROUP\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_320_ALIMDOCJOBS...\")\n",
    "    AUD_320_ALIMDOCJOBS(config, db, parsed_files_properties, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_320_ALIMDOCJOBS\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_323_ALIMELEMENTNODEFILTER...\")\n",
    "    AUD_323_ALIMELEMENTNODEFILTER(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_323_ALIMELEMENTNODEFILTER\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_324_ALIMMETADATAFILTER...\")\n",
    "    AUD_324_ALIMMETADATAFILTER(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_324_ALIMMETADATAFILTER\", start_time)\n",
    "\n",
    "        # start_time = time.time()\n",
    "    logging.info(\"Starting AUD_304_ALIMMETADATA...\")\n",
    "    AUD_304_ALIMMETADATA(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_304_ALIMMETADATA\", start_time)\n",
    "\n",
    "\n",
    "    # Optionally, you can add a final log or print statement indicating that all jobs have finished.\n",
    "    logging.info(\"All jobs have been executed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from jobs import *\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='database_operations.log',\n",
    "    level=logging.DEBUG,  # Changed to DEBUG to capture all messages\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w'  # Ensure the file is overwritten each time for clean logs\n",
    ")\n",
    "\n",
    "def log_execution_time(job_name, start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(f\"Execution time for {job_name}: {execution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    # logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)\n",
    "    db.connect_JDBC()\n",
    "\n",
    "    # Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    # Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    # logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "    items_directory = config.get_param('Directories', 'items_directory')\n",
    "    xml_parser = XMLParser()\n",
    "    parsed_files_data = xml_parser.loop_parse_items(items_directory)\n",
    "\n",
    "    parsed_files_properties = xml_parser.loop_parse_properties(items_directory)\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_properties}\")\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_data}\")\n",
    " \n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_307_ALIMINPUTTABLE...\")\n",
    "    # AUD_307_ALIMINPUTTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    # log_execution_time(\"AUD_307_ALIMINPUTTABLE\", start_time)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Initialize XMLParser and parse screenshot files from the directory\u001b[39;00m\n\u001b[0;32m     26\u001b[0m xml_parser \u001b[38;5;241m=\u001b[39m XMLParser()  \u001b[38;5;66;03m# Initialize with required arguments if needed\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m parsed_files_items \u001b[38;5;241m=\u001b[39m \u001b[43mxml_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_parse_screenshots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreenshots_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Log the parsed screenshot data for debugging\u001b[39;00m\n\u001b[0;32m     30\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsed Files Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_files_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sonia\\Desktop\\SQOPS_SERVER_PY\\SQOPS_SERVER_PY\\Local_to_brut\\XML_parse.py:469\u001b[0m, in \u001b[0;36mloop_parse_screenshots\u001b[1;34m(self, screenshots_directory)\u001b[0m\n\u001b[0;32m    467\u001b[0m     project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(parts[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    468\u001b[0m     job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(parts[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.item\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m     parsed_files_data\u001b[38;5;241m.\u001b[39mappend((project_name, job_name, parsed_data))\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\xml\\etree\\ElementTree.py:1204\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \n\u001b[0;32m   1197\u001b[0m \u001b[38;5;124;03m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m tree \u001b[38;5;241m=\u001b[39m ElementTree()\n\u001b[1;32m-> 1204\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\xml\\etree\\ElementTree.py:558\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    556\u001b[0m close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 558\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m     close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "# Load configuration from config.yaml\n",
    "config_file = \"config.yaml\"\n",
    "config = Config(config_file)\n",
    "\n",
    "# Retrieve JDBC parameters and create a Database instance\n",
    "jdbc_params = config.get_jdbc_parameters()\n",
    "logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "# Initialize Database instance and set JDBC parameters\n",
    "db = Database(jdbc_params)\n",
    "db.set_jdbc_parameters(jdbc_params)\n",
    "db.connect_JDBC()  # Test the JDBC connection\n",
    "\n",
    "# Get the screenshots directory from configuration\n",
    "screenshots_directory = config.get_param('Directories', 'screenshots_directory')\n",
    "logging.debug(f\"screenshots_directory: {screenshots_directory}\")\n",
    "\n",
    "# Initialize XMLParser and parse screenshot files from the directory\n",
    "xml_parser = XMLParser()  # Initialize with required arguments if needed\n",
    "parsed_files_items = xml_parser.loop_parse_screenshots(screenshots_directory)\n",
    "\n",
    "# Log the parsed screenshot data for debugging\n",
    "logging.debug(f\"Parsed Files Data: {parsed_files_items}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "import logging\n",
    "from jobs import *\n",
    "\n",
    "def main():\n",
    "    db = None\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)  # Set JDBC parameters if needed\n",
    "    db.connect_JDBC()  # Test the JDBC connection\n",
    "\n",
    "    #  Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    #  Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "\n",
    "    # Step 3: Parse screenshot files from the directory\n",
    "    screenshots_directory = config.get_param('Directories', 'screenshots_directory')\n",
    "\n",
    "    if not os.path.isdir(screenshots_directory):\n",
    "        logging.error(\"Directory not found: %s\", screenshots_directory)\n",
    "        return\n",
    "\n",
    "    xml_parser = XMLParser()\n",
    "\n",
    "    # Assuming the `loop_parse_screenshots` method parses all screenshot XMLs in the directory\n",
    "    parsed_files_items = xml_parser.loop_parse_screenshots(screenshots_directory)\n",
    "    AUD_701_CONVERTSCREENSHOT(config, db, parsed_files_items,execution_date,local_to_dbbrut_query_results)\n",
    "    if parsed_files_items:\n",
    "        logging.info(\"Parsed screenshot data: %s\", parsed_files_items)  # Log parsed data\n",
    "    else:\n",
    "        logging.warning(\"No screenshot data found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)  # Set up logging\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from jobs import *\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='database_operations.log',\n",
    "    level=logging.DEBUG,  # Changed to DEBUG to capture all messages\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w'  # Ensure the file is overwritten each time for clean logs\n",
    ")\n",
    "\n",
    "def log_execution_time(job_name, start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(f\"Execution time for {job_name}: {execution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    # logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)\n",
    "    db.connect_JDBC()\n",
    "\n",
    "    # Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    # Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    # logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "    items_directory = config.get_param('Directories', 'items_directory')\n",
    "    xml_parser = XMLParser()\n",
    "    parsed_files_data = xml_parser.loop_parse_items(items_directory)\n",
    "    print (parsed_files_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from jobs import *\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='database_operations.log',\n",
    "    level=logging.DEBUG,  # Changed to DEBUG to capture all messages\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w'  # Ensure the file is overwritten each time for clean logs\n",
    ")\n",
    "\n",
    "def log_execution_time(job_name, start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(f\"Execution time for {job_name}: {execution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    # logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)\n",
    "    db.connect_JDBC()\n",
    "\n",
    "    # Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    # Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    # logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "    items_directory = config.get_param('Directories', 'items_directory')\n",
    "    xml_parser = XMLParser()\n",
    "    parsed_files_data = xml_parser.loop_parse_items(items_directory)\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_data}\")\n",
    "\n",
    "    # Job execution without a loop\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_301_ALIMELEMENTNODE...\")\n",
    "    AUD_301_ALIMELEMENTNODE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_301_ALIMELEMENTNODE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_302_ALIMCONTEXTJOB...\")\n",
    "    AUD_302_ALIMCONTEXTJOB(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_302_ALIMCONTEXTJOB\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_303_ALIMNODE...\")\n",
    "    AUD_303_ALIMNODE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_303_ALIMNODE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_303_BIGDATA_PARAMETERS...\")\n",
    "    AUD_303_BIGDATA_PARAMETERS(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_303_BIGDATA_PARAMETERS\", start_time)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_305_ALIMVARTABLE_XML...\")\n",
    "    AUD_305_ALIMVARTABLE_XML(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_305_ALIMVARTABLE_XML\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_305_ALIMVARTABLE...\")\n",
    "    AUD_305_ALIMVARTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_305_ALIMVARTABLE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_306_ALIMOUTPUTTABLE...\")\n",
    "    AUD_306_ALIMOUTPUTTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_306_ALIMOUTPUTTABLE\", start_time)\n",
    "\n",
    "    #i need to update it\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_307_ALIMINPUTTABLE_XML...\")\n",
    "    # AUD_307_ALIMINPUTTABLE_XML(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    # log_execution_time(\"AUD_307_ALIMINPUTTABLE_XML\", start_time)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_307_ALIMINPUTTABLE...\")\n",
    "    AUD_307_ALIMINPUTTABLE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_307_ALIMINPUTTABLE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_308_ALIMCONNECTIONCOMPONENT...\")\n",
    "    AUD_308_ALIMCONNECTIONCOMPONENT(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_308_ALIMCONNECTIONCOMPONENT\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_309_ALIMELEMENTPARAMETER...\")\n",
    "    AUD_309_ALIMELEMENTPARAMETER(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_309_ALIMELEMENTPARAMETER\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_309_ALIMROUTINES...\")\n",
    "    AUD_309_ALIMROUTINES(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_309_ALIMROUTINES\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_310_ALIMLIBRARY...\")\n",
    "    AUD_310_ALIMLIBRARY(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_310_ALIMLIBRARY\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_311_ALIMELEMENTVALUENODE...\")\n",
    "    AUD_311_ALIMELEMENTVALUENODE(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_311_ALIMELEMENTVALUENODE\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_312_ALIMJOBFILS...\")\n",
    "    AUD_312_ALIMJOBFILS(config, db, parsed_files_data, execution_date)\n",
    "    log_execution_time(\"AUD_312_ALIMJOBFILS\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_314_ALIMSUBJOBS_OPT...\")\n",
    "    AUD_314_ALIMSUBJOBS_OPT(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_314_ALIMSUBJOBS_OPT\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_315_DELETEINACTIFNODES...\")\n",
    "    AUD_315_DELETEINACTIFNODES(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_315_DELETEINACTIFNODES\", start_time)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_317_ALIMJOBSERVERPROPRETY...\")\n",
    "    # AUD_317_ALIMJOBSERVERPROPRETY(config, db, parsed_files_data, items_directory)\n",
    "    # log_execution_time(\"AUD_317_ALIMJOBSERVERPROPRETY\", start_time)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # logging.info(\"Starting AUD_318_ALIMCONFQUARTZ...\")\n",
    "    # AUD_318_ALIMCONFQUARTZ(config, db, parsed_files_data, items_directory)\n",
    "    # log_execution_time(\"AUD_318_ALIMCONFQUARTZ\", start_time)\n",
    "\n",
    "    parsed_files_properties = xml_parser.loop_parse_properties(items_directory)\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_properties}\")\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_319_ALIMDOCCONTEXTGROUP...\")\n",
    "    AUD_319_ALIMDOCCONTEXTGROUP(config, db, parsed_files_properties)\n",
    "    log_execution_time(\"AUD_319_ALIMDOCCONTEXTGROUP\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_320_ALIMDOCJOBS...\")\n",
    "    AUD_320_ALIMDOCJOBS(config, db, parsed_files_properties, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_320_ALIMDOCJOBS\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_323_ALIMELEMENTNODEFILTER...\")\n",
    "    AUD_323_ALIMELEMENTNODEFILTER(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_323_ALIMELEMENTNODEFILTER\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_324_ALIMMETADATAFILTER...\")\n",
    "    AUD_324_ALIMMETADATAFILTER(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_324_ALIMMETADATAFILTER\", start_time)\n",
    "\n",
    "    # Step 3: Parse screenshot files from the directory\n",
    "    screenshots_directory = config.get_param('Directories', 'screenshots_directory')\n",
    "    # Assuming the `loop_parse_screenshots` method parses all screenshot XMLs in the directory\n",
    "    parsed_files_items = xml_parser.loop_parse_screenshots(screenshots_directory)\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_701_CONVERTSCREENSHOT...\")\n",
    "    AUD_701_CONVERTSCREENSHOT(config, db, parsed_files_items,execution_date,local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_701_CONVERTSCREENSHOT\", start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_304_ALIMMETADATA...\")\n",
    "    AUD_304_ALIMMETADATA(config, db, parsed_files_data, execution_date, local_to_dbbrut_query_results)\n",
    "    log_execution_time(\"AUD_304_ALIMMETADATA\", start_time)\n",
    "    \n",
    "\n",
    "    # Optionally, you can add a final log or print statement indicating that all jobs have finished.\n",
    "    logging.info(\"All jobs have been executed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC Driver: com.mysql.cj.jdbc.Driver\n",
      "JDBC URL: jdbc:mysql://localhost:3306/sqops_dataraise?allowLoadLocalInfile=true&characterEncoding=utf8\n",
      "JDBC User: root\n",
      "JDBC JAR: C:/Users/sonia/Downloads/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0/mysql-connector-j-9.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from jobs import *\n",
    "from config import Config  # Assuming Config class is defined in config.py\n",
    "from XML_parse import XMLParser  # Importing the XMLParser class\n",
    "from database import Database  # Assuming Database class is defined in database.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='database_operations.log',\n",
    "    level=logging.DEBUG,  # Changed to DEBUG to capture all messages\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w'  # Ensure the file is overwritten each time for clean logs\n",
    ")\n",
    "\n",
    "def log_execution_time(job_name, start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    logging.info(f\"Execution time for {job_name}: {execution_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    config_file = \"config.yaml\"\n",
    "    config = Config(config_file)\n",
    "\n",
    "    # Retrieve JDBC parameters and create a Database instance\n",
    "    jdbc_params = config.get_jdbc_parameters()\n",
    "    # logging.debug(f\"JDBC Parameters: {jdbc_params}\")\n",
    "\n",
    "    db = Database(jdbc_params)\n",
    "    db.set_jdbc_parameters(jdbc_params)\n",
    "    db.connect_JDBC()\n",
    "\n",
    "    # Get the execution date\n",
    "    execution_date_query = config.get_param('queries', 'TRANSVERSE_QUERY_LASTEXECUTIONDATE')\n",
    "    execution_date = db.get_execution_date(execution_date_query)\n",
    "    logging.info(f\"Execution Date: {execution_date}\")\n",
    "\n",
    "    # Execute LOCAL_TO_DBBRUT_QUERY\n",
    "    local_to_dbbrut_query = config.get_param('queries', 'LOCAL_TO_DBBRUT_QUERY')\n",
    "    logging.info(f\"Executing query: {local_to_dbbrut_query}\")\n",
    "    local_to_dbbrut_query_results = db.execute_query(local_to_dbbrut_query)\n",
    "    # logging.debug(f\"local_to_dbbrut_query_results: {local_to_dbbrut_query_results}\")\n",
    "\n",
    "    items_directory = config.get_param('Directories', 'items_directory')\n",
    "    xml_parser = XMLParser()\n",
    "    parsed_files_data = xml_parser.loop_parse_items(items_directory)\n",
    "\n",
    "    # parsed_files_properties = xml_parser.loop_parse_properties(items_directory)\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_properties}\")\n",
    "    # logging.debug(f\"Parsed Files Data: {parsed_files_data}\")\n",
    " \n",
    "\n",
    "    start_time = time.time()\n",
    "    logging.info(\"Starting AUD_323_ALIMELEMENTNODEFILTER...\")\n",
    "    AUD_323_ALIMELEMENTNODEFILTER(config, db, parsed_files_data)\n",
    "    log_execution_time(\"AUD_323_ALIMELEMENTNODEFILTER\", start_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
